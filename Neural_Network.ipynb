{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network.ipynb",
      "provenance": [],
      "mount_file_id": "1-_HF24Lml7njwqkv6Vm2SDcsRunPTV7D",
      "authorship_tag": "ABX9TyPoQ5zVW9NWXaJN8Lp20P8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibaso/Project2_quan.nt173312/blob/master/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMA81Ber9Hs_",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network\n",
        "Lấy dữ liệu ở file ở dạng ma trận thưa\n",
        "Chuyển dữ liệu sang kiểu tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMjygD0Q8dF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLr16DTihHV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def load_data(data_path, vocab_size):\n",
        "  with open(data_path, encoding = 'latin1') as f:\n",
        "    d_lines = f.read().splitlines()\n",
        "  data,labels = [],[]\n",
        "  for data_id, line in enumerate(d_lines):\n",
        "    vector = [0.0 for _ in range(vocab_size)]\n",
        "    features = line.split('<fff>')\n",
        "    label, doc_id = int(features[0]), int(features[1])\n",
        "    for token in features[2].split():\n",
        "      index, value = int(token.split(':')[0]), float(token.split(':')[1])\n",
        "      vector[index] = value\n",
        "    data.append(vector)\n",
        "    labels.append(label)\n",
        "  return torch.tensor(data), torch.tensor(labels)\n",
        "\n",
        "with open('/content/drive/My Drive/Data_Colab/words_idf.txt', encoding = 'latin1') as f:\n",
        "  vocab_size = len(f.read().splitlines())\n",
        "X_train, Y_train = load_data(\n",
        "    '/content/drive/My Drive/Data_Colab/train_tf_idf_vector.txt', vocab_size)\n",
        "X_test,Y_test = load_data(\n",
        "    '/content/drive/My Drive/Data_Colab/test_tf_idf_vector.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwkQKuj7z-f",
        "colab_type": "text"
      },
      "source": [
        "- Xây dựng các tham số cho mạng sử dụng torch.nn.Linear gồm các weight và bias cho từng tầng\n",
        "- Shuffle dữ liệu rồi tách ra thành các batch. Mỗi lần sẽ thực hiện lan truyền tiến, tính lỗi cho toàn bộ phần tử trong batch. Sau đó, cập nhật các tham số của mô hình\n",
        "- Lan truyền tiến (forward): tầng ẩn sử dụng hàm kích hoạt là sigmoid(x) = 1/(1+exp(-x)), tầng đầu ra sử dụng hàm softmax(xi) = exp(xi)/∑j exp(xj)\n",
        "- Tính lỗi loss dựa trên đầu ra của lan truyền tiến và nhãn thực tế của ví dụ sử dụng hàm cross_entropy\n",
        "- loss.backward tính gradient\n",
        "- Sử dụng torch.optim.Adam để cập nhật tham số dựa trên gradient tính được"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE1LpxsYU7B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "class NeuronNetwork(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self._vocab_size = vocab_size\n",
        "    self._hidden_size = hidden_size\n",
        "    self._num_classes = num_classes\n",
        "\n",
        "  #xay dung cau truc mang\n",
        "  def build_graph(self):\n",
        "    self._hidden_layer = torch.nn.Linear(self._vocab_size, self._hidden_size)\n",
        "    self._output_layer = torch.nn.Linear(self._hidden_size, self._num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.sigmoid(self._hidden_layer(x))\n",
        "    x = F.softmax(self._output_layer(x), dim = 1)\n",
        "    return x\n",
        "\n",
        "  def fit(self, X_train, Y_train, batch_size, max_epochs=50 ,learning_rate=1e-2, threshold=1e-3):\n",
        "    self.build_graph()\n",
        "    dataset = TensorDataset(X_train, Y_train)\n",
        "    data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "    opt = torch.optim.Adam(params = self.parameters(), lr = learning_rate)\n",
        "    last_loss = 0\n",
        "    for epoch in range(max_epochs):\n",
        "      new_loss = 0\n",
        "      for data,labels in data_loader:\n",
        "        self.zero_grad()\n",
        "        #lan truyen tien, tinh dau ra\n",
        "        prediced = self.forward(data)\n",
        "        #xac dinh loi\n",
        "        loss = F.cross_entropy(prediced, labels)\n",
        "        new_loss += loss\n",
        "        #lan truyen nguoc\n",
        "        loss.backward()\n",
        "        #cap nhat tham so\n",
        "        opt.step()\n",
        "      new_loss = new_loss / len(data_loader)\n",
        "      print('round: {}, loss: {}'.format(epoch, new_loss))\n",
        "      if abs(last_loss - new_loss) <= threshold:\n",
        "        return\n",
        "      last_loss=new_loss\n",
        "\n",
        "  def predict(self, X):\n",
        "    return torch.argmax(self.forward(X), dim = 1)\n",
        "\n",
        "  def compute_accuracy(self,predicted,expected):\n",
        "    return (predicted == expected).float().mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRh3Rl9K7hlq",
        "colab_type": "text"
      },
      "source": [
        "Huấn luyện mạng neural và tính độ chính xác trên tập huấn luyện với tập thử nghiệm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMXZc6A3xJ6B",
        "colab_type": "code",
        "outputId": "4035e558-6f90-42ce-89f6-4423f5f96147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from time import time\n",
        "t=time()\n",
        "NN = NeuronNetwork(\n",
        "    vocab_size = vocab_size,\n",
        "    hidden_size = 30,\n",
        "    num_classes = 20\n",
        "    )\n",
        "NN.fit(\n",
        "    X_train = X_train,\n",
        "    Y_train = Y_train,\n",
        "    batch_size = 60,\n",
        "    max_epochs = 50,\n",
        "    learning_rate = 1e-2,\n",
        "    threshold = 1e-3\n",
        "    )\n",
        "print('training time:',time()-t,'s')\n",
        "predicted = NN.predict(X_train)\n",
        "print('train accuracy:', NN.compute_accuracy(predicted, Y_train))\n",
        "predicted = NN.predict(X_test)\n",
        "print('test accuracy:', NN.compute_accuracy(predicted, Y_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round: 0, loss: 2.8042428493499756\n",
            "round: 1, loss: 2.4033281803131104\n",
            "round: 2, loss: 2.2484819889068604\n",
            "round: 3, loss: 2.1497304439544678\n",
            "round: 4, loss: 2.1281681060791016\n",
            "round: 5, loss: 2.105760097503662\n",
            "round: 6, loss: 2.090346336364746\n",
            "round: 7, loss: 2.0862843990325928\n",
            "round: 8, loss: 2.0843913555145264\n",
            "round: 9, loss: 2.083629846572876\n",
            "training time: 14.8424711227417 s\n",
            "train accuracy: tensor(0.9958)\n",
            "test accuracy: tensor(0.8343)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Mu54uX7UoE",
        "colab_type": "text"
      },
      "source": [
        "Các tham số của mạng sau khi huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QsJ_byNu7HI",
        "colab_type": "code",
        "outputId": "7cf07c4f-d526-408d-e7ac-9055fff9be73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('hidden layer weight:', NN._hidden_layer.weight.shape)\n",
        "print(NN._hidden_layer.weight)\n",
        "print('hidden layer bias:', NN._hidden_layer.bias.shape)\n",
        "print(NN._hidden_layer.bias)\n",
        "print('output layer weight:', NN._output_layer.weight.shape)\n",
        "print(NN._output_layer.weight)\n",
        "print('output layer bias:', NN._output_layer.bias.shape)\n",
        "print(NN._output_layer.bias)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden layer weight: torch.Size([30, 14612])\n",
            "Parameter containing:\n",
            "tensor([[-0.5120,  0.3229, -0.2952,  ...,  0.0392,  0.5703, -0.0040],\n",
            "        [-0.5765, -0.4505,  0.3326,  ...,  0.2473, -0.2460, -0.0065],\n",
            "        [-0.1677, -0.4114,  0.0455,  ...,  0.0970,  0.4613,  0.0048],\n",
            "        ...,\n",
            "        [-0.4443, -0.1872, -0.0102,  ..., -0.5484, -0.5428, -0.0010],\n",
            "        [ 0.4402,  0.0920, -0.2620,  ..., -0.1826, -0.3659,  0.0035],\n",
            "        [-0.4814,  0.0925, -0.3154,  ..., -0.3219, -0.2417, -0.0070]],\n",
            "       requires_grad=True)\n",
            "hidden layer bias: torch.Size([30])\n",
            "Parameter containing:\n",
            "tensor([ 3.2821e-01,  2.9508e-02,  1.5489e-01,  4.0406e-02,  3.1571e-01,\n",
            "         2.4742e-01,  4.0878e-01,  7.5129e-02,  3.3925e-01,  5.0604e-01,\n",
            "         2.0069e-01,  1.9289e-01,  1.4610e-01,  3.8981e-01,  5.5341e-02,\n",
            "         1.0784e-01,  2.7814e-01,  3.0716e-01,  2.8899e-01, -4.1495e-02,\n",
            "         5.1494e-02,  2.5715e-02,  8.0200e-02,  3.5032e-02,  2.8047e-01,\n",
            "         1.2714e-01,  1.9629e-01,  1.9580e-01, -2.6725e-04,  7.0405e-02],\n",
            "       requires_grad=True)\n",
            "output layer weight: torch.Size([20, 30])\n",
            "Parameter containing:\n",
            "tensor([[-1.9548e+00,  1.4915e+00,  1.4989e+00, -7.3345e-02, -1.7359e+00,\n",
            "         -2.3750e+00, -5.1565e-01,  9.5004e-01, -9.8695e-01, -2.5412e+00,\n",
            "         -3.5370e+00,  1.9342e+00, -2.0976e+00, -3.3578e-01,  2.0664e+00,\n",
            "          1.4690e+00, -2.1648e+00, -2.9673e+00,  2.4152e+00,  1.5999e+00,\n",
            "          1.0413e+00,  1.9979e+00,  4.7613e-01,  5.5927e-01, -2.0632e+00,\n",
            "          5.5947e-01,  8.8252e-01, -2.1260e+00, -3.2061e+00, -1.6716e-01],\n",
            "        [ 1.1415e+00,  1.8802e+00,  1.8007e+00, -4.1375e-01, -3.3855e-01,\n",
            "          1.8338e+00, -2.5664e+00, -1.7982e+00, -9.7857e-01, -1.6777e+00,\n",
            "          2.0025e+00,  2.2684e+00,  1.7465e+00, -1.4889e+00,  1.5086e+00,\n",
            "          1.4461e+00, -2.7390e+00,  2.0816e+00, -1.0572e+00, -1.4183e+00,\n",
            "         -1.9757e+00,  3.9014e-01,  1.3486e+00, -2.0457e+00, -2.0509e+00,\n",
            "         -2.0732e+00, -2.6247e+00, -1.9748e-01,  1.5852e+00, -1.6944e+00],\n",
            "        [-2.1773e+00, -6.0855e-01,  1.8714e+00,  1.2544e+00,  1.3108e+00,\n",
            "         -1.4185e+00, -1.9011e+00,  1.0277e+00, -2.6271e+00,  1.9352e+00,\n",
            "         -1.0290e+00, -1.4850e+00,  2.3234e+00, -8.6527e-01,  2.0297e+00,\n",
            "         -2.4045e+00,  1.4494e+00,  6.9353e-01, -1.5998e+00, -2.6647e+00,\n",
            "          6.0701e-01,  2.0041e+00,  1.3423e+00, -2.8124e+00,  1.3603e+00,\n",
            "         -1.7017e+00, -3.9856e-01, -2.0815e+00, -2.7102e-02,  2.2518e-01],\n",
            "        [-2.5240e+00, -2.5252e+00, -1.3535e+00,  1.5350e+00, -2.2033e+00,\n",
            "         -7.3849e-01,  2.5730e+00,  1.8425e+00,  1.9948e+00, -1.8957e+00,\n",
            "          1.5007e+00, -2.0010e+00, -1.3977e-01, -2.0174e+00,  7.9299e-01,\n",
            "          1.6082e+00,  9.3215e-01,  1.8047e+00, -6.4181e-01, -1.3454e+00,\n",
            "          1.1018e+00,  1.6510e+00,  1.4226e+00, -1.4867e+00, -1.9677e+00,\n",
            "          1.1357e+00, -2.3557e+00, -2.6739e+00,  1.6269e+00, -2.5668e+00],\n",
            "        [-4.1200e-01,  9.8644e-01, -1.5635e+00,  1.7073e+00,  8.7957e-01,\n",
            "         -1.6205e+00,  1.0526e+00,  1.3725e+00, -1.8006e+00,  5.4330e-01,\n",
            "          7.0882e-01,  3.9170e-01, -1.1470e+00, -3.1764e+00, -4.3187e-01,\n",
            "          5.8509e-01,  1.2602e+00,  5.5345e-01,  2.7808e+00,  7.8466e-02,\n",
            "          8.6011e-01, -1.8558e+00, -1.4455e+00, -1.1891e+00, -2.5744e+00,\n",
            "         -1.9307e+00, -2.2037e+00,  1.8990e+00,  1.2112e+00,  7.4370e-01],\n",
            "        [ 1.2964e+00,  1.8169e+00,  1.1565e+00, -3.1448e-01,  2.1955e+00,\n",
            "          1.2537e+00,  2.8292e+00, -9.5073e-01, -1.5616e+00, -2.2358e+00,\n",
            "          4.4236e-01, -2.6478e+00, -7.3419e-01, -3.9558e-01, -3.2532e-03,\n",
            "         -3.8814e-01, -2.3919e-01,  1.0716e+00, -1.3293e+00, -3.3050e+00,\n",
            "         -1.0529e-02, -1.9215e+00,  1.5241e+00,  2.0791e+00, -5.2750e-01,\n",
            "         -2.8920e+00,  1.4000e+00,  8.1285e-01, -1.9937e+00, -2.0762e+00],\n",
            "        [-1.0269e-01, -2.1604e+00, -1.6295e+00,  1.7445e+00,  2.0513e+00,\n",
            "          6.7755e-01, -1.5126e+00,  1.3597e+00,  1.4272e+00,  1.6701e+00,\n",
            "          1.0866e+00, -1.9372e+00,  1.6702e+00,  1.2393e+00, -1.0761e+00,\n",
            "         -2.6315e+00, -2.3656e+00,  1.8305e+00,  2.1592e+00,  3.5802e-01,\n",
            "         -2.0204e+00,  8.8960e-01, -1.3507e+00,  1.8876e+00, -1.4809e+00,\n",
            "         -1.8410e+00, -1.8322e+00, -1.7832e+00, -9.4614e-01,  1.1202e+00],\n",
            "        [ 1.4461e+00, -1.5236e+00,  1.6401e+00,  1.2588e+00, -2.0228e+00,\n",
            "          1.2460e+00, -1.3678e+00,  1.5568e+00, -1.6419e+00, -1.4239e+00,\n",
            "         -6.5231e-02,  1.5750e+00, -5.2322e-01, -1.3896e+00,  1.4534e+00,\n",
            "         -2.3124e+00,  1.5661e+00, -1.3543e+00, -9.0456e-01,  1.6759e+00,\n",
            "         -1.2497e+00, -1.5479e+00, -2.3880e+00,  1.2530e+00, -1.3988e+00,\n",
            "         -2.0751e+00,  1.1833e+00, -1.0504e+00,  1.3752e+00,  1.4387e+00],\n",
            "        [-1.8972e+00,  9.4607e-01,  8.9526e-01,  1.2623e+00, -1.6988e+00,\n",
            "         -1.5849e+00,  8.9341e-01, -1.8744e+00,  1.5278e+00,  1.4530e+00,\n",
            "         -1.5087e+00, -2.0115e+00,  1.3592e+00, -7.4437e-01,  1.1097e+00,\n",
            "          4.3531e-01, -2.0351e+00, -1.8351e+00, -1.9377e+00,  9.7657e-01,\n",
            "          1.1190e+00, -1.8080e+00, -1.5920e+00,  1.1595e+00, -5.3614e-01,\n",
            "         -1.6657e+00,  9.8650e-01,  1.3553e+00,  1.0029e+00,  1.2655e+00],\n",
            "        [ 1.4585e+00,  7.4296e-01,  6.4259e-01, -1.5134e+00, -1.9073e+00,\n",
            "          1.0533e+00,  1.1965e+00,  1.7199e+00, -1.3815e+00,  1.6972e+00,\n",
            "         -1.5990e+00, -1.6430e+00,  1.3701e+00,  1.4212e+00, -1.5838e+00,\n",
            "          4.0474e-01, -1.6884e+00, -1.2840e+00,  1.7708e+00,  1.0879e+00,\n",
            "         -1.6472e+00, -1.1120e+00,  2.0963e-01, -1.8484e+00,  1.0774e+00,\n",
            "         -1.0908e+00,  7.1804e-01, -1.1689e+00,  4.0379e-01, -2.1663e+00],\n",
            "        [-1.5556e+00, -1.8178e+00,  8.4042e-01, -6.5331e-01, -8.1856e-01,\n",
            "          1.1401e+00,  1.0542e+00, -1.6241e+00,  1.3152e+00,  8.7767e-01,\n",
            "         -1.5510e+00,  1.1707e+00,  7.5290e-02,  1.1781e+00, -1.4822e+00,\n",
            "         -1.5608e+00,  7.8136e-01,  1.3358e+00,  1.1648e+00, -1.7930e+00,\n",
            "          1.0429e+00, -1.8664e+00, -1.8192e+00, -6.7548e-01,  1.0660e+00,\n",
            "          1.0398e+00, -1.5936e+00,  1.2294e+00,  1.0002e+00, -1.7447e+00],\n",
            "        [-1.9780e+00,  1.4692e+00, -1.4738e+00, -1.2878e+00,  1.5404e+00,\n",
            "         -1.3419e+00, -1.9563e+00,  1.7366e+00, -2.0424e+00, -1.4279e+00,\n",
            "          1.5832e+00, -1.4375e+00, -1.3811e+00, -1.9729e+00, -1.2084e+00,\n",
            "          1.7404e+00, -1.8354e+00, -7.3793e-01, -1.7930e+00, -3.0161e-01,\n",
            "          1.8432e+00, -8.0074e-01,  1.5773e+00,  1.2108e+00,  1.8481e+00,\n",
            "          1.0618e+00, -6.7334e-01, -1.3834e+00, -1.0444e+00,  1.5804e+00],\n",
            "        [ 3.1146e-01, -2.1821e+00,  5.0037e-01, -6.2915e-01, -3.9642e-01,\n",
            "          1.5743e+00, -1.7622e+00,  4.6069e-01,  9.2655e-01,  7.0414e-01,\n",
            "         -1.4151e+00,  1.0528e+00,  2.0296e+00, -2.2047e+00,  8.0053e-01,\n",
            "          2.1224e+00,  1.0527e+00, -2.3804e+00, -1.2521e+00, -1.1269e+00,\n",
            "         -4.7477e-01,  1.5169e+00,  1.3479e+00,  2.7986e+00, -1.4071e+00,\n",
            "          3.2651e-02, -3.2520e+00, -3.7300e-01, -1.2127e+00,  1.3065e-01],\n",
            "        [ 1.3261e+00,  1.5138e+00, -1.6345e+00, -1.6217e+00, -1.6577e+00,\n",
            "          1.7558e+00, -1.4096e+00, -1.3705e+00,  1.6875e+00, -9.4699e-01,\n",
            "          3.5629e-01, -1.8704e+00, -1.6356e+00, -1.3352e+00,  1.8335e+00,\n",
            "         -1.5143e+00,  1.5227e+00, -1.1972e+00, -1.3105e+00,  1.3846e+00,\n",
            "         -1.2320e+00,  1.6918e+00, -1.2500e+00,  1.3707e+00,  1.5119e+00,\n",
            "          8.6765e-01, -1.8253e+00,  1.7694e+00, -1.7762e+00, -1.4568e+00],\n",
            "        [ 1.0359e+00, -2.2688e+00, -1.5445e+00,  1.1406e+00,  1.2454e+00,\n",
            "          1.1069e+00, -2.2445e+00,  2.1465e-01, -1.1768e+00, -1.8769e+00,\n",
            "          1.0672e+00,  1.0046e+00, -2.1720e+00,  1.8817e+00, -1.7115e+00,\n",
            "          9.5001e-01,  6.0213e-01, -2.0511e+00, -1.3801e+00, -1.6153e+00,\n",
            "          1.1165e+00,  9.1169e-01,  7.1128e-01, -3.2503e-01, -2.0186e+00,\n",
            "          6.3712e-01,  7.9693e-01,  1.4446e+00,  6.5432e-01, -1.7890e-02],\n",
            "        [ 2.3642e+00, -1.3464e+00,  8.1512e-01, -2.3283e+00, -1.7538e+00,\n",
            "         -1.5511e+00,  1.5346e+00, -1.8175e+00,  4.9868e-02,  2.6108e+00,\n",
            "         -7.7405e-01,  1.6343e+00,  1.2509e-01, -2.0316e+00, -1.4395e+00,\n",
            "         -2.4033e+00,  1.3741e+00, -9.7265e-01, -1.5083e+00, -1.9235e+00,\n",
            "          1.1427e+00,  1.1934e+00,  1.6395e+00, -1.9772e+00, -1.2803e+00,\n",
            "          1.6103e+00,  1.3510e+00, -1.8226e+00, -2.6401e+00,  1.5819e+00],\n",
            "        [-2.1674e+00,  1.2903e+00, -2.5946e+00, -1.4365e+00,  1.2621e+00,\n",
            "         -1.7432e+00, -2.0951e+00, -1.9419e+00, -1.8774e+00, -1.4592e+00,\n",
            "         -1.3852e+00,  1.6422e+00,  2.1624e+00,  1.1594e+00, -1.1575e+00,\n",
            "         -1.6276e+00, -2.9856e-01, -1.9866e+00, -1.7124e+00,  1.5811e+00,\n",
            "         -1.9004e+00, -7.3405e-02,  1.4111e+00, -1.7912e+00,  1.5797e+00,\n",
            "          1.4631e+00,  1.4729e+00,  1.9274e+00,  1.8113e+00, -1.2856e+00],\n",
            "        [ 1.2162e+00,  4.5851e-01, -1.9719e+00, -1.4551e+00,  1.3330e+00,\n",
            "         -1.6616e+00,  1.2037e+00, -2.2108e+00,  1.3234e+00, -1.7650e+00,\n",
            "          1.2103e+00, -8.4722e-01, -1.6287e+00,  1.1928e+00, -1.9250e+00,\n",
            "          1.3442e+00,  1.1815e+00,  1.5207e+00,  1.5195e+00,  8.0305e-01,\n",
            "         -2.0813e+00,  4.2491e-01, -2.1060e+00, -2.4630e+00,  7.8654e-01,\n",
            "          4.2573e-01,  6.8420e-01, -1.9575e+00, -1.8640e+00,  9.5057e-01],\n",
            "        [ 5.2950e-01,  7.4401e-01, -1.3008e+00, -2.5208e+00,  7.2145e-01,\n",
            "         -2.1795e+00,  8.3994e-01,  1.8770e+00,  1.4602e+00, -3.5555e-01,\n",
            "         -2.2098e+00,  5.0827e-01, -2.4225e+00,  8.7447e-01, -1.9932e+00,\n",
            "         -7.5129e-01, -4.4766e-01, -1.2664e+00, -1.3208e+00,  7.7665e-01,\n",
            "          1.2031e-01, -1.4016e+00, -1.9099e+00,  1.2271e+00,  1.2914e+00,\n",
            "          1.0543e+00,  1.2530e+00,  1.5020e+00, -6.4915e-01,  1.2144e+00],\n",
            "        [-1.1792e+00,  7.6884e-01,  1.1152e+00, -7.7454e-01, -1.0924e+00,\n",
            "         -1.0714e+00, -2.0951e-02, -2.2164e+00, -7.9664e-01, -2.1245e-01,\n",
            "          6.3310e-01,  4.8003e-01, -1.5046e+00,  6.6058e-01,  4.4633e-01,\n",
            "          5.5674e-01, -7.2175e-01,  1.8537e+00, -3.2984e-01,  8.7631e-01,\n",
            "         -8.0094e-02,  1.2064e-01,  1.0743e+00,  5.7980e-02,  1.7570e-01,\n",
            "          1.1663e+00,  1.3422e+00, -1.5077e+00,  5.2396e-01, -3.1565e-01]],\n",
            "       requires_grad=True)\n",
            "output layer bias: torch.Size([20])\n",
            "Parameter containing:\n",
            "tensor([ 0.1139,  0.2060,  0.6313,  0.1513,  0.7781,  0.9851,  0.0454, -0.0452,\n",
            "        -0.3103, -0.0970, -0.2629,  0.4114,  0.1807,  0.4088, -0.6995,  0.5079,\n",
            "         0.2855, -0.4151, -0.0788,  0.0933], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKvfd968VDem",
        "colab_type": "text"
      },
      "source": [
        "# SVMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXbys4Zl9_qO",
        "colab_type": "code",
        "outputId": "4aeba7f5-eec0-4186-ece1-263b5f54d218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def compute_accuracy(predicted,expected):\n",
        "\tmatches=np.equal(predicted,expected)\n",
        "\taccuracy=np.sum(matches)/len(expected)\n",
        "\treturn accuracy\n",
        "\n",
        "train_data = csr_matrix(X_train)\n",
        "test_data = csr_matrix(X_test)\n",
        "\n",
        "classifier=SVC(\n",
        "\t\tC=10,\n",
        "\t\tkernel='rbf',\n",
        "\t\tgamma=0.1,\n",
        "\t\ttol=1e-3,\n",
        "\t\tverbose=True\n",
        "    )\n",
        "classifier.fit(train_data, np.array(Y_train))\n",
        "\n",
        "predicted = classifier.predict(train_data)\n",
        "accuracy = compute_accuracy(predicted = predicted, expected = np.array(Y_train))\n",
        "print('train accuracy:',accuracy)\n",
        "predicted = classifier.predict(test_data)\n",
        "accuracy = compute_accuracy(predicted = predicted, expected = np.array(Y_test))\n",
        "print('test accuracy:',accuracy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]train accuracy: 0.9967297153968535\n",
            "test accuracy: 0.8272703133297928\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}