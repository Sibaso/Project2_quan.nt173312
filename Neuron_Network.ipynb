{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuron_Network.ipynb",
      "provenance": [],
      "mount_file_id": "1-_HF24Lml7njwqkv6Vm2SDcsRunPTV7D",
      "authorship_tag": "ABX9TyPSehzDij4atXzZ0UHaaqIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibaso/Project2_quan.nt173312/blob/master/Neuron_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMA81Ber9Hs_",
        "colab_type": "text"
      },
      "source": [
        "# Neuron Network\n",
        "Lấy dữ liệu ở file ở dạng ma trận thưa\n",
        "Chuyển dữ liệu sang kiểu tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMjygD0Q8dF3",
        "colab_type": "code",
        "outputId": "b9a0c67f-9a6d-44c9-f591-153e6337a3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLr16DTihHV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def load_data(data_path, vocab_size):\n",
        "  with open(data_path, encoding = 'latin1') as f:\n",
        "    d_lines = f.read().splitlines()\n",
        "  data,labels = [],[]\n",
        "  for data_id, line in enumerate(d_lines):\n",
        "    vector = [0.0 for _ in range(vocab_size)]\n",
        "    features = line.split('<fff>')\n",
        "    label, doc_id = int(features[0]), int(features[1])\n",
        "    for token in features[2].split():\n",
        "      index, value = int(token.split(':')[0]), float(token.split(':')[1])\n",
        "      vector[index] = value\n",
        "    data.append(vector)\n",
        "    labels.append(label)\n",
        "  return torch.tensor(data), torch.tensor(labels)\n",
        "\n",
        "with open('/content/drive/My Drive/Data_Colab/words_idf.txt', encoding = 'latin1') as f:\n",
        "  vocab_size = len(f.read().splitlines())\n",
        "X_train, Y_train = load_data(\n",
        "    '/content/drive/My Drive/Data_Colab/train_tf_idf_vector.txt', vocab_size)\n",
        "X_test,Y_test = load_data(\n",
        "    '/content/drive/My Drive/Data_Colab/test_tf_idf_vector.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnahmTP-YOn",
        "colab_type": "text"
      },
      "source": [
        "Shuffle dữ liệu rồi tách ra thành các batch, mỗi lần sẽ thực hiện forward và backward cho toàn bộ phần tử trong batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcFxRPug-NRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size = 50, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwkQKuj7z-f",
        "colab_type": "text"
      },
      "source": [
        "- Xây dựng các tham số cho mạng sử dụng torch.nn.Linear gồm các weight và bias cho từng tầng\n",
        "- Lan truyền tiến (forward): tầng ẩn sử dụng hàm kích hoạt là sigmoid(x) = 1/(1+exp(-x)), tầng đầu ra sử dụng hàm softmax(xi) = exp(xi)/∑j exp(xj)\n",
        "- Tính lỗi dựa trên đầu ra của lan truyền tiến và nhãn thực tế của ví dụ sử dụng hàm cross_entropy\n",
        "- Sử dụng torch.optim.Adam để cập nhật tham số dựa trên lỗi tính được"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE1LpxsYU7B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuronNetwork(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self._vocab_size = vocab_size\n",
        "    self._hidden_size = hidden_size\n",
        "    self._num_classes = num_classes\n",
        "\n",
        "  #xay dung cau truc mang\n",
        "  def build_graph(self):\n",
        "    self._hidden_layer = torch.nn.Linear(self._vocab_size, self._hidden_size)\n",
        "    self._output_layer = torch.nn.Linear(self._hidden_size, self._num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.sigmoid(self._hidden_layer(x))\n",
        "    x = F.softmax(self._output_layer(x), dim = 1)\n",
        "    return x\n",
        "\n",
        "  def fit(self, max_epochs, data_loader, learning_rate, threshold):\n",
        "    self.build_graph()\n",
        "    opt = torch.optim.Adam(params = self.parameters(), lr = learning_rate)\n",
        "    last_loss = 0\n",
        "    for epoch in range(max_epochs):\n",
        "      new_loss = 0\n",
        "      for data,labels in data_loader:\n",
        "        self.zero_grad()\n",
        "        #lan truyen tien, tinh dau ra\n",
        "        prediced = self.forward(data)\n",
        "        #xac dinh loi\n",
        "        loss = F.cross_entropy(prediced, labels)\n",
        "        new_loss += loss\n",
        "        #lan truyen nguoc\n",
        "        loss.backward()\n",
        "        #cap nhat tham so\n",
        "        opt.step()\n",
        "      new_loss = new_loss / len(data_loader)\n",
        "      print('round: {}, loss: {}'.format(epoch, new_loss))\n",
        "      if abs(last_loss - new_loss) <= threshold:\n",
        "        return\n",
        "      last_loss=new_loss\n",
        "\n",
        "  def predict(self, X):\n",
        "    return torch.argmax(self.forward(X), dim = 1)\n",
        "\n",
        "  def compute_accuracy(self,predicted,expected):\n",
        "    return (predicted == expected).float().mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRh3Rl9K7hlq",
        "colab_type": "text"
      },
      "source": [
        "Huấn luyện mạng neuron và tính độ chính xác trên tập huấn luyện với tập thử nghiệm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMXZc6A3xJ6B",
        "colab_type": "code",
        "outputId": "6730f8dd-83c6-42c0-8f2d-3039dda095c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "NN = NeuronNetwork(\n",
        "    vocab_size = vocab_size,\n",
        "    hidden_size = 50,\n",
        "    num_classes = 20\n",
        "    )\n",
        "NN.fit(\n",
        "    max_epochs = 20,\n",
        "    data_loader = train_data_loader,\n",
        "    learning_rate = 1e-2,\n",
        "    threshold = 1e-3\n",
        "    )\n",
        "predicted = NN.predict(X_train)\n",
        "print('train accuracy:', NN.compute_accuracy(predicted, Y_train))\n",
        "predicted = NN.predict(X_test)\n",
        "print('test accuracy:', NN.compute_accuracy(predicted, Y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round: 0, loss: 2.750535488128662\n",
            "round: 1, loss: 2.2983288764953613\n",
            "round: 2, loss: 2.1613996028900146\n",
            "round: 3, loss: 2.128693103790283\n",
            "round: 4, loss: 2.1092355251312256\n",
            "round: 5, loss: 2.0916218757629395\n",
            "round: 6, loss: 2.086991310119629\n",
            "round: 7, loss: 2.084772825241089\n",
            "round: 8, loss: 2.083759307861328\n",
            "round: 9, loss: 2.083280563354492\n",
            "train accuracy: tensor(0.9958)\n",
            "test accuracy: tensor(0.8411)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Mu54uX7UoE",
        "colab_type": "text"
      },
      "source": [
        "Các tham số của mạng sau khi huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QsJ_byNu7HI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f53e888-5bbf-4273-b2c7-aadc337ac5d4"
      },
      "source": [
        "print('hidden layer weight:', NN._hidden_layer.weight.shape)\n",
        "print(NN._hidden_layer.weight)\n",
        "print('hidden layer bias:', NN._hidden_layer.bias.shape)\n",
        "print(NN._hidden_layer.bias)\n",
        "print('output layer weight:', NN._output_layer.weight.shape)\n",
        "print(NN._output_layer.weight)\n",
        "print('output layer bias:', NN._output_layer.bias.shape)\n",
        "print(NN._output_layer.bias)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden layer weight: torch.Size([50, 14612])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0582,  0.2224, -0.9582,  ...,  0.7449,  0.6211, -0.0066],\n",
            "        [ 0.4620,  0.3086, -0.3577,  ..., -0.0907, -0.4680,  0.0040],\n",
            "        [ 0.2072,  0.7601,  0.1113,  ...,  0.0922, -0.0977,  0.0078],\n",
            "        ...,\n",
            "        [-0.1153,  0.0858, -0.1707,  ..., -0.2093,  0.1613, -0.0064],\n",
            "        [-0.3302, -0.4415,  0.0305,  ..., -0.0348, -0.5109,  0.0026],\n",
            "        [ 0.4458, -0.2334,  0.3221,  ...,  0.1679,  0.0893, -0.0076]],\n",
            "       requires_grad=True)\n",
            "hidden layer bias: torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([ 0.2047,  0.1319,  0.1494, -0.0049,  0.0114,  0.1514,  0.2834,  0.1989,\n",
            "         0.2642,  0.1540,  0.0760,  0.0251,  0.1785, -0.0126, -0.0044, -0.1902,\n",
            "        -0.2549, -0.1546,  0.3797,  0.0419, -0.0953,  0.2001,  0.1680,  0.2071,\n",
            "         0.2524,  0.2435,  0.0105,  0.2383,  0.3663,  0.0298, -0.0239,  0.1038,\n",
            "        -0.2932, -0.0515,  0.1688,  0.1071,  0.3186,  0.2966,  0.0319,  0.0960,\n",
            "         0.1147,  0.1338, -0.0038, -0.0120, -0.0761,  0.2133,  0.1566,  0.1250,\n",
            "         0.2142, -0.0154], requires_grad=True)\n",
            "output layer weight: torch.Size([20, 50])\n",
            "Parameter containing:\n",
            "tensor([[-1.9738e+00,  4.9402e-01,  1.0358e+00, -4.1410e-01, -8.2451e-01,\n",
            "         -3.4596e-01,  9.2807e-01, -2.0069e-01,  1.0874e+00,  5.1663e-01,\n",
            "          3.4049e-01,  8.3071e-01, -7.4967e-02, -2.7092e-01, -3.1523e-01,\n",
            "          5.8273e-01,  1.3854e+00, -3.9802e-01,  4.5139e-01,  1.3693e+00,\n",
            "          1.0235e+00, -1.9284e+00, -1.4594e+00, -1.8465e-01, -1.4077e-01,\n",
            "         -1.8953e+00,  8.2465e-01, -1.5871e+00, -1.9537e+00, -1.2730e+00,\n",
            "         -4.0264e-01, -1.5309e+00,  1.6508e+00, -1.2859e+00,  9.6906e-01,\n",
            "          3.6702e-01, -1.0267e+00, -3.6207e-01, -2.7196e-01,  8.3605e-01,\n",
            "          7.2739e-01, -1.9861e+00, -5.2809e-03,  9.8899e-01,  1.0250e-02,\n",
            "          5.9535e-01,  7.3922e-01,  3.4691e-01,  4.3323e-01,  2.7304e-01],\n",
            "        [-1.5633e+00, -1.1625e+00, -1.6370e+00, -8.6768e-01,  1.2096e+00,\n",
            "         -1.2007e+00, -1.0786e+00, -4.3784e-01,  2.2073e+00,  4.8690e-01,\n",
            "          1.2272e-01, -1.3552e+00, -4.9819e-01,  1.6443e+00, -7.5813e-01,\n",
            "         -1.0044e+00, -5.6615e-01, -1.2360e+00,  4.7138e-01,  1.6546e+00,\n",
            "         -8.8549e-01, -6.5558e-03,  1.2673e+00, -9.4581e-01, -1.2790e+00,\n",
            "         -7.7357e-01, -2.7807e-01,  9.4636e-01,  1.5797e+00,  1.1299e+00,\n",
            "          1.9264e+00, -1.2315e+00, -9.1705e-02, -3.3872e-01, -2.0138e+00,\n",
            "         -1.1604e+00,  7.7433e-01,  1.0433e+00, -1.0687e+00,  7.4047e-01,\n",
            "         -2.8699e-01,  1.2983e+00,  1.3715e+00,  1.6164e+00, -8.0816e-01,\n",
            "          9.7579e-01, -6.6433e-01, -1.1339e+00, -1.6432e+00,  1.2193e+00],\n",
            "        [-3.4824e-01, -8.0103e-01,  1.4220e+00,  1.5065e+00, -1.6039e+00,\n",
            "          1.2022e+00,  5.3184e-01,  1.7000e+00, -4.4687e-01, -1.4739e+00,\n",
            "          1.0269e+00, -1.6721e+00,  1.1173e+00,  1.1221e+00,  7.5606e-01,\n",
            "          9.7145e-01, -1.3025e+00, -1.0055e+00, -1.5810e+00, -3.0819e-01,\n",
            "          9.7450e-01, -1.1617e+00,  7.2969e-01,  1.0410e+00, -1.1581e+00,\n",
            "          1.1454e+00, -1.6370e+00,  1.5919e+00,  1.9271e+00, -1.2029e+00,\n",
            "          1.2207e+00, -1.2595e+00,  4.3419e-01, -7.4500e-01, -4.3067e-01,\n",
            "         -1.5884e+00,  1.0067e+00,  9.1835e-01, -1.2951e+00, -1.0577e+00,\n",
            "          6.3258e-01,  6.2606e-01, -1.5189e+00, -1.2929e+00, -4.4022e-01,\n",
            "         -1.4508e+00, -1.5983e+00, -1.8210e+00,  1.4445e+00, -1.2673e-01],\n",
            "        [ 1.3155e+00,  1.3024e+00, -2.3029e-01, -2.1732e-01, -1.5792e+00,\n",
            "          6.2807e-01, -1.1079e+00, -1.2418e+00, -4.4978e-01, -1.2121e+00,\n",
            "         -1.1099e+00, -1.6885e+00,  1.4389e+00,  3.0204e-01, -1.4605e+00,\n",
            "          1.1334e+00,  1.1008e+00,  1.1829e+00, -1.3267e+00,  1.2063e+00,\n",
            "          1.1004e+00, -1.4304e+00,  6.5649e-01, -6.5985e-01,  3.4392e-01,\n",
            "          1.1784e+00,  9.6291e-01, -1.1304e+00, -6.6922e-01,  1.2307e+00,\n",
            "          1.2871e+00,  2.9309e-01,  1.2929e+00,  9.3106e-01, -9.2599e-01,\n",
            "          3.0936e-05, -1.2082e+00, -9.3149e-01, -1.5729e+00, -1.5059e+00,\n",
            "         -1.3303e+00,  9.9238e-01, -1.5112e+00, -1.0372e+00,  1.5238e+00,\n",
            "          9.2202e-01, -1.6578e+00, -1.5985e-01, -1.1690e+00,  9.8498e-01],\n",
            "        [ 1.4546e-01,  2.0230e-01,  1.2142e+00,  5.8670e-01,  1.3466e+00,\n",
            "         -1.9362e+00, -1.1747e+00,  1.3819e+00, -1.6078e+00,  4.1760e-01,\n",
            "          1.0995e+00,  1.6474e+00, -1.8860e+00,  9.6231e-01,  1.3686e+00,\n",
            "          1.0790e+00,  1.1010e+00,  1.1054e+00,  5.5119e-01, -1.6620e-01,\n",
            "         -4.1372e-02, -1.0908e+00, -1.0278e+00, -3.3839e-01, -1.5880e+00,\n",
            "          9.7748e-01, -1.5063e+00,  4.3850e-01, -7.0028e-01,  1.0841e+00,\n",
            "          7.5167e-01, -1.9189e-01,  5.1714e-01,  1.1896e+00, -1.4067e+00,\n",
            "         -1.4297e+00, -1.8478e+00, -1.2863e+00, -7.5050e-01, -1.7754e+00,\n",
            "         -9.6743e-01,  1.0142e+00, -1.2973e+00,  1.3682e+00, -3.5108e-01,\n",
            "         -1.7078e+00,  1.4236e+00, -7.7564e-02, -8.2348e-01,  1.4982e-01],\n",
            "        [ 1.0994e+00,  1.8960e+00, -9.2300e-01, -1.2252e+00, -6.7589e-01,\n",
            "         -1.0166e+00, -1.2039e+00,  6.9987e-01, -1.0329e-01, -1.3984e+00,\n",
            "         -7.7447e-01, -1.2927e-01, -1.6554e+00,  5.7396e-01, -1.7197e+00,\n",
            "          1.6485e+00, -1.1542e+00, -1.0963e+00,  1.8705e+00,  1.5847e+00,\n",
            "          1.1296e+00,  4.5466e-01,  1.0090e+00,  1.4318e-01, -1.2794e+00,\n",
            "         -7.9176e-01,  7.8963e-01, -6.9452e-01, -1.3823e-01, -1.3867e+00,\n",
            "         -5.8292e-01, -5.4494e-01, -1.4029e+00, -6.0516e-01,  1.4994e+00,\n",
            "         -1.6035e+00, -1.2334e+00,  1.1758e+00, -1.4105e+00,  4.6228e-01,\n",
            "          1.6817e+00,  1.4389e+00,  1.5692e+00, -9.6383e-01, -1.2553e+00,\n",
            "         -2.1012e+00,  9.3656e-02, -1.5831e+00,  1.3552e+00,  1.4509e+00],\n",
            "        [ 1.1415e+00, -1.2750e+00,  1.4680e+00,  7.6827e-01,  1.8360e-01,\n",
            "         -4.1929e-01, -3.3178e-01, -1.3037e+00, -1.2126e+00, -1.2939e+00,\n",
            "         -1.8298e+00, -1.1622e+00, -7.3499e-01,  4.0859e-01,  1.0619e+00,\n",
            "         -1.4976e+00, -9.1406e-01, -1.0974e+00,  1.1044e+00,  1.1451e+00,\n",
            "         -1.0027e+00,  1.3530e+00,  9.7982e-01,  1.4820e+00, -1.0385e+00,\n",
            "          1.0766e+00,  7.6966e-01, -1.6215e+00,  1.4502e+00,  9.4667e-01,\n",
            "         -3.9254e-01,  1.4732e+00,  7.1418e-01, -1.1826e+00, -1.1693e+00,\n",
            "          1.4972e+00,  7.7096e-01, -1.6201e+00,  1.5308e-01, -1.6499e+00,\n",
            "          1.1884e+00,  4.4692e-01,  5.0521e-01,  1.1186e+00,  3.1942e-02,\n",
            "         -1.5023e+00, -1.5332e+00,  1.3933e+00, -1.8674e+00, -1.1727e+00],\n",
            "        [-5.8866e-02,  4.0307e-01, -7.7694e-01,  5.2157e-01,  1.4778e+00,\n",
            "          6.3314e-01,  1.0699e+00, -1.0187e+00, -2.0733e+00,  7.2423e-01,\n",
            "          7.0174e-01, -4.3964e-01,  1.4373e-01, -1.2598e+00, -3.7378e-01,\n",
            "         -1.1006e+00, -7.7974e-01,  8.6169e-01, -1.6444e+00, -1.3286e+00,\n",
            "          1.3741e+00,  1.1462e+00, -1.2142e+00, -4.9943e-01, -1.7305e-01,\n",
            "          7.4763e-01,  9.5544e-01, -2.0012e+00, -6.4448e-01,  5.3582e-01,\n",
            "         -7.4203e-01,  1.2127e+00, -1.2022e+00, -1.0057e+00,  2.2882e-01,\n",
            "         -7.8061e-01,  7.5683e-01,  9.8838e-01,  1.3507e+00, -1.3310e+00,\n",
            "          1.2970e+00,  1.6451e+00, -7.7230e-01, -1.2770e+00, -1.1376e+00,\n",
            "         -4.3729e-01,  1.2529e+00,  7.8998e-01,  7.1982e-01, -1.4737e+00],\n",
            "        [-5.4758e-01, -1.2571e+00, -1.1207e+00,  1.2173e+00, -9.1725e-01,\n",
            "          1.0590e+00, -8.6776e-01, -5.2896e-01, -1.1311e+00, -6.2081e-01,\n",
            "         -1.1457e+00,  1.2048e+00, -1.4109e+00, -1.2907e+00, -9.0480e-01,\n",
            "          4.5048e-01, -1.0243e+00, -1.3760e+00, -1.3868e+00, -1.1510e+00,\n",
            "          4.5671e-01,  3.8652e-01, -6.7183e-01,  1.1874e+00,  1.3561e+00,\n",
            "          9.3254e-01,  9.6371e-01, -1.3751e+00, -8.6326e-01,  1.0702e+00,\n",
            "         -9.1908e-01, -6.2674e-01, -8.2551e-01,  1.3514e+00, -9.3344e-01,\n",
            "          8.2264e-01, -1.3007e+00,  1.3594e+00,  1.3453e+00,  1.0529e+00,\n",
            "          1.1865e+00,  9.1337e-01,  1.4328e+00, -1.2465e+00,  1.2422e+00,\n",
            "          8.7247e-01, -1.1302e+00, -1.5480e+00, -7.3482e-01,  1.1136e+00],\n",
            "        [ 4.0821e-01, -1.1916e+00,  8.1920e-01, -1.2361e+00,  5.7049e-01,\n",
            "          5.3436e-01,  1.0938e+00,  8.8722e-01,  6.9477e-01,  7.5782e-01,\n",
            "         -1.2328e+00,  6.3215e-01,  5.4265e-01, -1.4144e+00, -1.1581e+00,\n",
            "         -1.2995e+00,  6.6748e-01, -1.1552e+00,  5.3131e-01, -1.1165e+00,\n",
            "         -1.2281e+00,  6.3412e-01,  8.4472e-01,  9.0781e-01,  4.6167e-01,\n",
            "         -1.0640e+00, -1.5504e+00,  6.0715e-01,  8.8377e-01,  7.7915e-01,\n",
            "          8.3438e-01,  3.9590e-01,  5.6255e-01, -1.0010e+00,  7.4343e-01,\n",
            "         -1.0245e+00, -1.3053e+00,  9.0995e-01,  6.2853e-01,  5.8389e-01,\n",
            "         -3.7571e-01, -1.0679e+00, -1.1061e+00, -1.2924e+00, -1.2338e+00,\n",
            "          6.0507e-01, -1.2050e+00,  4.8178e-01,  6.2241e-01,  2.0526e-01],\n",
            "        [-8.6893e-01,  9.9427e-01,  8.9736e-01,  8.7457e-01,  5.0443e-01,\n",
            "          6.7745e-01, -9.2978e-01,  6.4863e-01, -1.1196e+00,  8.5801e-01,\n",
            "         -1.4526e+00,  6.8955e-01,  4.2476e-01, -1.5382e+00,  1.2206e-01,\n",
            "         -1.5995e+00,  7.2730e-01,  6.7080e-01,  5.1964e-01, -1.1064e+00,\n",
            "          4.0448e-01,  4.3885e-01, -1.0263e+00, -1.1944e-01,  9.3002e-01,\n",
            "         -1.4687e+00, -1.4235e+00, -1.3560e+00,  1.0848e+00,  6.4009e-01,\n",
            "         -1.3519e+00,  2.8198e-02, -1.5079e+00,  9.3461e-01,  7.3299e-01,\n",
            "         -1.1050e+00,  1.0535e+00, -9.0180e-01, -1.4951e+00,  6.4155e-01,\n",
            "          8.0775e-01, -2.3462e-01, -1.5508e+00,  9.1629e-01,  7.9646e-01,\n",
            "          6.3552e-01,  7.6627e-01, -1.5702e+00, -1.4641e+00,  7.6170e-01],\n",
            "        [ 1.3307e+00, -9.1727e-01, -8.0216e-01, -1.0668e+00,  1.3375e+00,\n",
            "         -1.5653e+00, -9.4612e-01,  1.7885e-01, -8.4020e-01, -3.4366e-01,\n",
            "          1.5357e+00, -6.7665e-01,  1.1705e+00,  1.2062e+00, -9.2856e-01,\n",
            "         -1.1694e+00,  1.2599e+00,  1.3238e+00, -1.8909e+00,  5.5379e-01,\n",
            "          7.0128e-01,  8.0227e-01, -6.7503e-01, -9.1423e-01, -1.5398e+00,\n",
            "         -1.4125e+00, -1.6364e-01,  3.5268e-02, -1.2059e+00, -1.2643e+00,\n",
            "         -1.0346e+00, -1.1545e+00,  1.3869e+00,  1.6311e-01,  6.1732e-01,\n",
            "          1.3857e+00, -6.1603e-01, -1.2539e+00, -7.8447e-01, -1.6627e+00,\n",
            "          1.5091e+00, -3.9503e-01,  1.3760e+00, -6.6896e-01, -7.3820e-01,\n",
            "          8.8514e-01, -1.1768e+00, -1.0575e+00,  1.3310e+00,  1.0726e+00],\n",
            "        [ 7.7714e-01, -1.4678e+00, -1.4015e+00,  9.9347e-01,  3.0677e-01,\n",
            "          6.1675e-01,  1.8689e+00,  6.0578e-01, -8.9119e-01, -9.9223e-01,\n",
            "         -5.1385e-01,  1.2678e+00, -1.6723e-01,  1.2825e+00, -8.6504e-01,\n",
            "         -1.4101e+00, -5.9544e-01, -6.7097e-02, -1.2358e+00,  3.1355e-01,\n",
            "          1.4588e+00,  1.1209e+00,  7.1471e-01, -1.8168e+00, -1.7478e+00,\n",
            "          7.1171e-01,  1.0676e+00,  1.4950e+00, -7.9753e-01, -1.6012e+00,\n",
            "          1.1450e+00,  1.2454e+00, -2.8190e-01, -2.5178e-01,  1.8942e-01,\n",
            "         -1.3725e+00, -1.4042e+00, -1.5063e+00,  1.1952e+00,  9.3110e-01,\n",
            "         -7.3612e-01, -1.2229e+00, -6.3471e-01, -1.9363e-01,  1.5094e+00,\n",
            "         -1.7685e+00, -1.9000e-02,  1.0639e+00, -1.7029e+00,  1.3817e+00],\n",
            "        [-1.1998e+00, -2.0866e-01, -1.6431e+00, -1.8295e+00, -1.6282e+00,\n",
            "          1.3366e+00, -2.8536e-01, -1.6414e+00,  4.5072e-01,  1.2775e+00,\n",
            "         -9.4645e-01, -1.0715e+00,  9.7669e-01,  1.5262e+00, -5.5505e-01,\n",
            "         -1.1144e+00,  1.8944e-01,  1.5022e+00,  1.5455e+00, -1.6510e+00,\n",
            "         -3.8235e-01, -7.1109e-01, -7.3674e-01, -5.0053e-01,  4.2211e-01,\n",
            "          1.0695e+00,  6.9108e-01,  1.4053e+00, -1.0311e+00, -7.3667e-01,\n",
            "          1.2364e+00, -9.9410e-01,  4.2197e-01,  2.0138e+00, -1.5841e+00,\n",
            "         -5.3712e-01,  1.3098e+00, -2.0350e-01,  1.3643e+00, -3.9568e-01,\n",
            "          1.4415e-01, -2.0399e+00, -4.3012e-01, -3.3126e-01, -9.7438e-01,\n",
            "          6.7140e-01,  3.3951e-01, -5.9342e-01,  1.2017e+00,  4.2399e-01],\n",
            "        [-5.4896e-01, -1.2721e+00, -1.0141e+00, -1.4238e+00, -1.3129e+00,\n",
            "          6.4763e-01,  5.7770e-01, -1.0095e+00,  1.0216e+00,  4.7461e-01,\n",
            "          9.8561e-01,  6.8094e-01, -1.2792e+00, -1.1660e+00,  7.4604e-01,\n",
            "          5.2191e-01,  6.2549e-01,  6.9300e-01, -1.2028e+00,  8.9759e-01,\n",
            "         -1.4257e+00, -1.3375e+00,  8.9303e-01, -1.1688e+00,  6.8713e-01,\n",
            "         -1.3231e+00,  5.4764e-01,  8.7843e-01,  9.1183e-01, -1.4201e+00,\n",
            "         -1.1965e+00,  7.6792e-01,  5.7339e-01,  6.3269e-01, -1.1593e+00,\n",
            "         -5.3100e-01,  6.0684e-01,  8.9888e-01,  6.0016e-01,  6.4640e-01,\n",
            "          8.4816e-01,  4.5542e-01, -4.3034e-01,  8.6391e-01,  8.5742e-01,\n",
            "         -1.2295e+00,  8.4059e-01,  7.1647e-01, -1.1398e+00, -1.4412e+00],\n",
            "        [ 1.5858e+00,  1.0124e+00, -9.8090e-01,  1.1168e+00, -1.2822e+00,\n",
            "         -1.3155e+00,  1.5099e+00,  1.2215e+00,  1.1557e+00,  1.0717e+00,\n",
            "          9.1041e-01, -1.4456e+00, -1.0523e+00,  1.3650e+00, -5.1930e-01,\n",
            "         -9.1808e-01, -1.5079e+00, -1.4539e+00,  1.2430e+00, -1.5156e+00,\n",
            "          3.8043e-01, -1.4353e+00, -8.8669e-01,  1.4151e+00,  1.2261e+00,\n",
            "          8.4817e-01,  7.7528e-02, -4.8602e-01, -4.2931e-01, -1.0261e+00,\n",
            "         -9.4205e-01, -1.0207e+00, -1.6041e+00, -1.0416e+00, -1.5598e+00,\n",
            "          9.7903e-01, -8.0005e-01, -7.2405e-01,  1.0268e+00, -1.2839e+00,\n",
            "         -1.4204e+00,  7.8085e-01, -1.3731e+00, -1.0397e+00,  8.9173e-01,\n",
            "          9.3941e-01,  9.7569e-01,  1.0351e+00,  7.6941e-01, -1.8904e+00],\n",
            "        [-1.4182e+00,  1.0283e+00, -1.2032e+00,  5.0041e-01, -1.0923e+00,\n",
            "         -1.5548e+00,  8.2149e-01,  1.1244e+00, -1.0935e+00,  9.7572e-01,\n",
            "         -6.4198e-01, -1.2474e+00,  8.4721e-01, -1.4485e+00,  1.0599e+00,\n",
            "          5.6024e-01,  7.2400e-01,  6.9730e-01, -1.3059e+00,  6.8881e-01,\n",
            "         -1.5224e+00,  9.4673e-01, -1.0446e+00, -1.0236e+00, -1.4125e+00,\n",
            "         -1.3876e+00,  8.6574e-01, -8.7862e-01, -1.0229e+00,  9.2854e-01,\n",
            "          1.2228e+00,  1.1565e+00,  7.3741e-01,  9.3819e-01,  1.1370e+00,\n",
            "          7.8859e-01,  1.0163e+00, -1.1558e+00,  8.5052e-01,  5.0127e-01,\n",
            "         -1.4508e+00, -1.7645e+00,  1.0184e+00, -1.3021e+00, -2.2953e-01,\n",
            "         -1.0513e+00,  9.0679e-01, -9.6680e-01,  8.3105e-01, -1.5475e+00],\n",
            "        [-1.2491e+00,  7.5658e-01,  9.9435e-01, -4.6058e-01,  7.7016e-01,\n",
            "          7.5303e-01, -1.1815e+00, -1.0594e+00,  7.7045e-01, -1.3138e+00,\n",
            "          7.6615e-01,  8.3743e-01,  9.1019e-01, -1.1805e+00,  8.6207e-01,\n",
            "          6.6480e-01, -1.3170e+00, -1.1459e+00,  6.2019e-01, -1.3080e+00,\n",
            "         -1.6744e+00, -1.3673e+00,  9.4474e-01,  9.2284e-01, -6.9337e-01,\n",
            "          1.0318e+00,  8.5406e-01,  8.6488e-01, -1.0323e+00, -1.2127e+00,\n",
            "         -7.3674e-01, -1.0701e+00, -1.5044e+00, -1.1901e+00,  7.9776e-01,\n",
            "          7.2665e-01,  8.4733e-01,  9.3934e-01, -1.2896e+00,  5.9945e-01,\n",
            "         -1.4321e+00, -1.2045e+00,  6.8521e-01,  9.2659e-01, -1.3214e+00,\n",
            "          5.6735e-01, -5.4346e-01,  6.6529e-01,  5.4830e-01, -1.4974e+00],\n",
            "        [ 3.2227e-01, -5.4483e-01, -6.3383e-01, -1.6805e+00,  7.8030e-01,\n",
            "         -1.3481e+00, -9.6249e-01, -1.2901e+00, -5.6398e-01, -6.8523e-01,\n",
            "          1.2594e+00, -6.4674e-01,  1.0217e-01,  6.4903e-01,  3.8596e-01,\n",
            "          1.3769e+00, -1.3599e+00,  1.3137e+00, -8.4782e-01, -1.8161e+00,\n",
            "          2.5291e-01,  1.4530e+00, -1.3461e+00, -9.3770e-01,  1.5582e+00,\n",
            "         -1.7738e+00, -5.6208e-01, -5.5201e-01,  1.0048e+00, -7.9082e-01,\n",
            "         -1.2679e+00,  1.9066e+00, -1.4494e+00, -1.5269e+00,  8.4097e-01,\n",
            "          1.2724e+00, -8.1779e-02, -6.6879e-01,  6.6959e-01,  1.0702e+00,\n",
            "         -1.4734e+00, -2.5042e+00,  1.3261e+00,  1.3944e+00,  1.3431e+00,\n",
            "          8.9697e-01, -5.0440e-01, -1.3830e-01,  3.2786e-01,  4.0612e-01],\n",
            "        [ 9.8632e-02,  8.1088e-01, -4.4748e-01,  8.2397e-01, -4.8254e-01,\n",
            "         -1.2561e-01, -6.7070e-01,  1.7547e-01,  3.1216e-01, -6.7601e-01,\n",
            "          1.0952e-01, -6.8697e-01, -3.8564e-01, -8.3704e-01,  7.9316e-01,\n",
            "          7.0673e-01, -9.9689e-01,  2.2405e-01,  4.0393e-01,  1.0713e-01,\n",
            "          1.5091e-02,  7.6606e-01, -2.8270e-01, -3.8127e-01,  9.9054e-01,\n",
            "          1.1349e-02, -1.3873e+00,  8.7260e-01, -1.6534e+00,  6.0642e-01,\n",
            "         -1.3859e+00, -1.5187e+00, -6.8116e-01,  1.0377e+00,  9.3120e-01,\n",
            "          9.5852e-01,  7.0257e-01, -6.5691e-01, -6.5104e-01,  1.1124e-01,\n",
            "         -1.1891e+00,  6.8001e-01,  1.0822e+00, -5.0087e-01, -1.1377e-01,\n",
            "          7.7936e-01,  3.9628e-01,  6.3808e-01,  5.7089e-01,  3.0859e-01]],\n",
            "       requires_grad=True)\n",
            "output layer bias: torch.Size([20])\n",
            "Parameter containing:\n",
            "tensor([ 0.1155,  0.2658,  0.2086,  0.2021, -0.0710,  0.5358,  0.0593,  0.2272,\n",
            "         0.0803, -0.1427, -0.1228,  0.4792,  0.0272,  0.3625, -0.2224,  0.0981,\n",
            "         0.0040, -0.1418,  0.2673, -0.1260], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKvfd968VDem",
        "colab_type": "text"
      },
      "source": [
        "# SVMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXbys4Zl9_qO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41139bfa-36cc-4472-f579-c9242c676a25"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def compute_accuracy(predicted,expected):\n",
        "\tmatches=np.equal(predicted,expected)\n",
        "\taccuracy=np.sum(matches)/len(expected)\n",
        "\treturn accuracy\n",
        "\n",
        "train_data = csr_matrix(X_train)\n",
        "test_data = csr_matrix(X_test)\n",
        "\n",
        "classifier=SVC(\n",
        "\t\tC=50,\n",
        "\t\tkernel='rbf',\n",
        "\t\tgamma=0.1,\n",
        "\t\ttol=1e-3,\n",
        "\t\tverbose=True\n",
        "    )\n",
        "classifier.fit(train_data,np.array(Y_train))\n",
        "predicted=classifier.predict(test_data)\n",
        "accuracy=compute_accuracy(predicted=predicted,expected=np.array(Y_test))\n",
        "print('accuracy:',accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]accuracy: 0.8250132766861391\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}